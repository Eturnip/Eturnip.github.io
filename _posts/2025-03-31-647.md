---
layout: post
title: "647"
date: 2025-03-31T00:00:00
categories: Blog
tags:
  - misc
---
I haven’t written about it here, because it didn’t seem relevant to what I write, or draw, or model, or whatever, but I do have some thoughts about generative AI. Some of them are even good.

There is a lot of backlash against generative AI, specifically the models and tools that create its version of imagery, music, and creative writing. It can be easy for advocates of these tools to claim that any criticism of gen AI tools comes from a place of sour grapes and whining. After all, they say, gen AI tools are coming for artists jobs. That is both a tiny bit right, and entirely wrong. Let me explain.

Generative AI tools, the kinds that create art, are fascinating. They can iterate on patterns, often starting from little more than pseudo-random noise, until they create an image or bit of music that is recognizable as art. That is, and you will have to admit this even if you don’t like the results it produces, amazing. I even think it can be useful, just not in the way that is currently getting a lot of buzz.

Much of the backlash against gen AI tools is that they, necessarily, use the art of human creators to do what they do. Human art is just fodder for the machine and much of it is stolen, as none of the original creators gave permission for their art to be fed into the AI model. This is all one hundred percent correct and true. Gen AI tools do copy from human artists, and those human artists should have the rights to their works respected. This isn’t just me stating how I feel about the whole situation, this is how copyright law in most of the world works. If a company duplicates your work, for any reason, you should be compensated for that, or at the very least, you should be aware of it. And Gen AI tools do duplicate the artwork, in sort of a weird mish-mashy, cuisinart sort of way, but it is, provably, copied into a digital data-model.

So the artsies got that one right. The companies behind Gen AI models do steal copyrighted works to build their systems. Which is stupid, since there are many-many sources of copyright free or licensable art available. It would have honestly cost them very little to operate on the right side of that whole issue. But that’s not even my problem with Gen AI tools. But maybe I should get into what I think they can be good for first.

Photoshop, and other digital image manipulation tools, have had something like a generative fill, or content aware fill, for quite a while. This tool does a similar thing as most Gen AI tools. It creates a new bit of image to patch in an area with new content. Say you had a photo of a beach with a lighthouse over on the right side. You like the photo, but wish it were about twenty percent wider and that the lighthouse sat closer to two thirds of the way across the composition and that there was more beach and rocks on the right side of the photo. Content aware fill can help you to accomplish that. It will create some new beach over on the right and do it’s best to blend it all in. Again, it’s pretty amazing. Now, these tools won’t do this automatically, and it will take the work of a skilled photo manipulator to do a really good job of it, but this is an example of an artist using Gen AI as a tool to do something that would have been difficult, or even impossible, without it. I’m certain that there are many examples of similar tools used for music production, film production, wood carving, tile design, etc, etc, etc. But at the core of the work will be a person making choices. And here is were I think a lot of the hyped Gen AI stuff will always come up short, no matter how much computer power you throw at them.

Humans are humans. We have been around for a few hundred thousand years. Other hominids, for a few million years before that. Animals that would eventually evolve into humans, maybe five hundred or so million years before that. That is a lot of time. A lot of iteration. A lot of refinement. Our brains run on a fraction of the power of a typical computer, but process information with a complexity that we struggle to comprehend and are no where near replicating in a digital model. When you tell a computer to create art, that is the problem that you are trying to solve. 

The problem is humans. The problem isn’t replicating an art style, or building a coherent song. The problem is people. Humans don’t even fully understand other humans, but we do know how to solve the human problem. We do know how to communicate, connect, and empathize. We have to, because solving the human problem is what keeps us alive. 

We instinctively know what choice of words, what series of notes, what daub of color, will strike another human emotionally. We know what makes us tick. Even if we can't always explain why.

I'm not even saying that there is anything special about humans. I think we are a solvable problem. I think an intelligence that isn't us, could relate and interact with us. It's just very, very hard. Much more difficult than our current AI tools are capable of solving. Humans are a more complicated problem than the hypsters are letting on.

We didn’t learn how to solve humans from our parents, we didn’t gradually build up a model for it as we grew. It is built into our cells. It’s fundamental to who we are as animals. It’s how we are built. It’s how we were built over millions and millions of years. It's the only way we have made it this far.

That’s it. That’s the problem that a generative AI art machine needs to solve if whoever created it wants it to churn out art that doesn’t feel synthetic to human eyes, ears, and thoughts. It needs to be human. Or at least a really good simulation of one. 

We ain’t there yet.

Current gen AI tools sort of average out all of the art that they have absorbed (stolen?) to present the viewer with something that seems similar to what a human would make. And of course it does, because humans already made all that art, it’s just been jumbled up and rearranged by a predictive algorithm to provide the nearest guess at what a human would have made. When it gets that guess right, it can look wonderful. It can be a useful tool. It can help an artist move a lighthouse a kilometer down the beach. When it gets it wrong, it will look exactly like what it is, a computers best approximation of what a human might have done. 

You know who solves that problem with a shockingly high success rate? Humans. It’s not that Gen AI is a bad tool. It’s not, in fact it can be a great tool. It’s just not being used to solve the right problems at the moment.
